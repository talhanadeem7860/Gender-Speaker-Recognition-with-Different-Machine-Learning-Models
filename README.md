Project Overview

This repository provides a comparative analysis of various machine learning models for the tasks of Gender Recognition and Speaker Recognition. The project uses a dataset of audio recordings to train and evaluate multiple classifiers, identifying the most effective models for these bio-acoustic tasks.

This project showcases a comprehensive machine learning comparison workflow:

Feature Extraction: Acoustic features that characterize a speaker's voice are extracted from the raw audio signals.

Model Training: Several different classification algorithms are trained on the same dataset. The models compared include:

k-Nearest Neighbors (k-NN)

Decision Tree

Support Vector Machine (SVM)

Ensemble methods (e.g., Bagged Trees)

Performance Evaluation: Each model's performance is systematically evaluated on an unseen test set to measure its accuracy for both gender and speaker identification.

Comparison: The final accuracies of all models are compared to determine the most suitable algorithm for this particular problem.
